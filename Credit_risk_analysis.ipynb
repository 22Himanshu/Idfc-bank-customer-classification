{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea0704c5-5f22-4bc9-869d-efbd0bb60052",
   "metadata": {},
   "source": [
    "# Credit Risk Analysis (Multi-class classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63dbefb-71b9-4120-ac40-9f7526c88d39",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fc35dc6-8dcc-4027-903c-70237d3e0a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import chi2_contingency\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
    "import warnings\n",
    "import os\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a550fd67-b256-4678-974f-24f2319056b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f99ad91-4121-4238-bb9e-f9adff969a97",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eaf2970-011b-414b-afcd-7043884cfa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7c652c01c250>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/himanshu/PycharmProjects/pythonProject/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m r1\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcase_study1.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m r2\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcase_study2.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject/.venv/lib/python3.11/site-packages/pandas/io/excel/_base.py:508\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 508\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_close:\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject/.venv/lib/python3.11/site-packages/pandas/io/excel/_base.py:1616\u001b[0m, in \u001b[0;36mExcelFile.parse\u001b[0;34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[1;32m   1576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\n\u001b[1;32m   1577\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1578\u001b[0m     sheet_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1596\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[1;32m   1597\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, DataFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, DataFrame]:\n\u001b[1;32m   1598\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m \u001b[38;5;124;03m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1614\u001b[0m \u001b[38;5;124;03m    >>> file.parse()  # doctest: +SKIP\u001b[39;00m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject/.venv/lib/python3.11/site-packages/pandas/io/excel/_base.py:778\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[0;34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[1;32m    775\u001b[0m     sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sheet_by_index(asheetname)\n\u001b[1;32m    777\u001b[0m file_rows_needed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calc_rows(header, index_col, skiprows, nrows)\n\u001b[0;32m--> 778\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sheet_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msheet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_rows_needed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(sheet, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# pyxlsb opens two TemporaryFiles\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     sheet\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject/.venv/lib/python3.11/site-packages/pandas/io/excel/_openpyxl.py:615\u001b[0m, in \u001b[0;36mOpenpyxlReader.get_sheet_data\u001b[0;34m(self, sheet, file_rows_needed)\u001b[0m\n\u001b[1;32m    613\u001b[0m data: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Scalar]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    614\u001b[0m last_row_with_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 615\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msheet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconverted_row\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_cell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwhile\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconverted_row\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconverted_row\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# trim trailing empty elements\u001b[39;49;00m\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_read_only.py:85\u001b[0m, in \u001b[0;36mReadOnlyWorksheet._cells_by_row\u001b[0;34m(self, min_col, min_row, max_col, max_row, values_only)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_source() \u001b[38;5;28;01mas\u001b[39;00m src:\n\u001b[1;32m     78\u001b[0m     parser \u001b[38;5;241m=\u001b[39m WorkSheetParser(src,\n\u001b[1;32m     79\u001b[0m                              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shared_strings,\n\u001b[1;32m     80\u001b[0m                              data_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mdata_only,\n\u001b[1;32m     81\u001b[0m                              epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mepoch,\n\u001b[1;32m     82\u001b[0m                              date_formats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39m_date_formats,\n\u001b[1;32m     83\u001b[0m                              timedelta_formats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39m_timedelta_formats)\n\u001b[0;32m---> 85\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmax_row\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_row\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "File \u001b[0;32m~/PycharmProjects/pythonProject/.venv/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:156\u001b[0m, in \u001b[0;36mWorkSheetParser.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m properties \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    138\u001b[0m     PRINT_TAG: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprint_options\u001b[39m\u001b[38;5;124m'\u001b[39m, PrintOptions),\n\u001b[1;32m    139\u001b[0m     MARGINS_TAG: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage_margins\u001b[39m\u001b[38;5;124m'\u001b[39m, PageMargins),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m \n\u001b[1;32m    152\u001b[0m }\n\u001b[1;32m    154\u001b[0m it \u001b[38;5;241m=\u001b[39m iterparse(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource) \u001b[38;5;66;03m# add a finaliser to close the source when this becomes possible\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtag_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtag\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtag_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdispatcher\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/xml/etree/ElementTree.py:1254\u001b[0m, in \u001b[0;36miterparse.<locals>.iterator\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m   1253\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1254\u001b[0m     \u001b[43mpullparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1255\u001b[0m root \u001b[38;5;241m=\u001b[39m pullparser\u001b[38;5;241m.\u001b[39m_close_and_return_root()\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m pullparser\u001b[38;5;241m.\u001b[39mread_events()\n",
      "File \u001b[0;32m/usr/lib/python3.11/xml/etree/ElementTree.py:1292\u001b[0m, in \u001b[0;36mXMLPullParser.feed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1292\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1294\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events_queue\u001b[38;5;241m.\u001b[39mappend(exc)\n",
      "File \u001b[0;32m/usr/lib/python3.11/xml/etree/ElementTree.py:1709\u001b[0m, in \u001b[0;36mXMLParser.feed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Feed encoded data to parser.\"\"\"\u001b[39;00m\n\u001b[1;32m   1708\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1709\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error \u001b[38;5;28;01mas\u001b[39;00m v:\n\u001b[1;32m   1711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raiseerror(v)\n",
      "File \u001b[0;32m../Modules/pyexpat.c:468\u001b[0m, in \u001b[0;36mEndElement\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3.11/xml/etree/ElementTree.py:1578\u001b[0m, in \u001b[0;36mXMLParser._setevents.<locals>.handler\u001b[0;34m(tag, event, append, end)\u001b[0m\n\u001b[1;32m   1576\u001b[0m     parser\u001b[38;5;241m.\u001b[39mStartElementHandler \u001b[38;5;241m=\u001b[39m handler\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1578\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandler\u001b[39m(tag, event\u001b[38;5;241m=\u001b[39mevent_name, append\u001b[38;5;241m=\u001b[39mappend,\n\u001b[1;32m   1579\u001b[0m                 end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_end):\n\u001b[1;32m   1580\u001b[0m         append((event, end(tag)))\n\u001b[1;32m   1581\u001b[0m     parser\u001b[38;5;241m.\u001b[39mEndElementHandler \u001b[38;5;241m=\u001b[39m handler\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "r1=pd.read_excel(\"case_study1.xlsx\")\n",
    "r2=pd.read_excel(\"case_study2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd52ec8f-39d0-4a8f-9420-f0ea860e49c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=r1.copy()\n",
    "df2=r2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed9bb17-7b8c-4cfe-96d9-d8520fc89dba",
   "metadata": {},
   "source": [
    "## Preprocessing of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037c5c60-330a-40f3-ac75-903c66e0d136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fbab5b-a6b9-4342-9c59-ea07a2d1c0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f382433-033c-4010-80d4-0ec21b4da920",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc0da20-ee04-427c-a19b-bdb2b0143227",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc2d3f-0669-40d7-b2b7-a2218d3f3a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80efa521-62ce-41f2-80a3-03b3b09e3417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f22d732-0cb4-48c9-8cb5-4e062b829cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe092306-b7d5-4d4c-9cc9-7c04323724f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1[\"Age_Oldest_TL\"].value_counts().get(-99999))\n",
    "print(df1[\"Age_Newest_TL\"].value_counts().get(-99999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e70263-d931-4cbe-8409-3875a2bc9acc",
   "metadata": {},
   "source": [
    "### In df1 \"Age_Oldest_TL\", \"Age_Newest_TL\" have -99999 as a value which denotes NULL value.\n",
    "### Since the count of these values is only 40 and we have around 52000 rows, I have decided to remove these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b84117-c4d8-4b23-9b03-a8509179d882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.loc[df1['Age_Newest_TL']!=-99999]\n",
    "df1=df1.loc[df1['Age_Oldest_TL']!=-99999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f920f5-d176-4a16-82f9-5affc6436924",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c69377-e131-46ec-999b-6f75180c7eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da0838d-eb72-4a67-b121-928988a05adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0559a21-edc8-4fb9-8766-91e71aba0c4b",
   "metadata": {},
   "source": [
    "### If we closely analyse, we have many columns in df2 which have NULL values indicated by -99999\n",
    "### We have to check the count for these Null values. Since we have 52000 rows, I am considering if the count of Null values > 10000 (20%), I will drop that column and if less I will just drop the rows with Null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e41ef5-527e-476f-abaf-f0f2c730e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_be_removed = []\n",
    "\n",
    "for i in df2.columns:\n",
    "    if df2.loc[df2[i] == -99999].shape[0] > 10000:\n",
    "        columns_to_be_removed .append(i)\n",
    "\n",
    "df2 = df2.drop(columns_to_be_removed, axis =1)\n",
    "for i in df2.columns:\n",
    "    df2 = df2.loc[ df2[i] != -99999 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9560bb5-7ba5-47c5-ac16-a204b2a2162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_be_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0724112-84f9-42ec-a4be-a544b6ae1bbd",
   "metadata": {},
   "source": [
    "### Now since we have 2 datasets, I will combine both datasets with a common column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b32d2a8-db73-4012-bc12-5fca3246beeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking common column names\n",
    "for i in list(df1.columns):\n",
    "    if i in list(df2.columns):\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c0139-5eaa-4800-aaa9-7b4d09f0fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes, inner join so that no nulls are present\n",
    "df = pd. merge ( df1, df2, how ='inner', left_on = ['PROSPECTID'], right_on = ['PROSPECTID'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f028ee-22d3-4a19-ac61-eb03dd7a2bf4",
   "metadata": {},
   "source": [
    "### We have our combined dataset now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a50e4-d7bb-4301-a061-c4f07ca2acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129e9fd2-9853-441e-94ee-74502e58a4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffaa127-915a-4d9f-b499-112d9c4e78c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1641775e-401f-493f-a3d8-599184a1c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2911fda6-1ce2-4878-9150-44f21e5a65e4",
   "metadata": {},
   "source": [
    "### Check how many columns are categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578a5b30-c5b2-4445-af4c-ef9c214f4661",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    if df[i].dtype == 'object':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08816c48-5699-4511-abb1-741a093774ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c488a607-0d94-46a0-95ea-3327d8ef7014",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e3a7f0-174c-454d-b79b-d0475f5acb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Approved_Flag contains 'P1', 'P2', 'P3', 'P4'\n",
    "flag_mapping = {'P1': 1, 'P2': 2, 'P3': 3, 'P4': 4}\n",
    "df['Approved_Flag_Num'] = df['Approved_Flag'].map(flag_mapping)\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Create the bar chart\n",
    "ax = sns.countplot(x='Approved_Flag_Num', data=df, palette='viridis', hue='Approved_Flag', legend=False)\n",
    "\n",
    "# Adjust x-axis labels to show original categorical values\n",
    "# Calculate bar width and center the labels\n",
    "xticks = [tick  for tick in range(len(flag_mapping))]\n",
    "\n",
    "# Update x-axis labels and positions\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(flag_mapping.keys())\n",
    "\n",
    "# Titles and labels\n",
    "plt.title('Count of Approved_Flag')\n",
    "plt.xlabel('Approved_Flag')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "df = df.drop(['Approved_Flag_Num'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3e351f-a509-44b7-9441-f72c878e955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "\n",
    "# Define the order for Approved_Flag categories\n",
    "approved_flag_order = ['P1', 'P2', 'P3', 'P4']\n",
    "\n",
    "# List of categorical variables\n",
    "categorical_vars = ['MARITALSTATUS', 'EDUCATION', 'GENDER']\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Loop through each categorical variable to create a bar plot\n",
    "for i, var in enumerate(categorical_vars, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.countplot(x=var, hue='Approved_Flag', data=df, hue_order=approved_flag_order, palette='viridis')\n",
    "    plt.title(f'Distribution of {var} by Approved_Flag')\n",
    "    plt.xlabel(var)\n",
    "    plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65382b75-124e-46b1-834a-05a7730d67f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "\n",
    "# Define the order for Approved_Flag categories\n",
    "approved_flag_order = ['P1', 'P2', 'P3', 'P4']\n",
    "\n",
    "# List of categorical variables to compare against Approved_Flag\n",
    "categorical_vars = ['MARITALSTATUS', 'EDUCATION', 'GENDER']\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Loop through each Approved_Flag category and plot its distribution for each categorical variable\n",
    "for i, flag in enumerate(approved_flag_order, 1):\n",
    "    for j, var in enumerate(categorical_vars, 1):\n",
    "        plt.subplot(len(approved_flag_order), len(categorical_vars), (i - 1) * len(categorical_vars) + j)\n",
    "        \n",
    "        # Filter data for the current Approved_Flag category\n",
    "        filtered_df = df[df['Approved_Flag'] == flag]\n",
    "        \n",
    "        # Plot the distribution of the secondary categorical variable\n",
    "        sns.countplot(x=var, data=filtered_df, hue=var, palette='viridis', legend=False)\n",
    "        plt.title(f'{var} for {flag}')\n",
    "        plt.xlabel(var)\n",
    "        plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3eaa92-8c42-4816-ab21-c62c00c11a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b8bdbb-8d86-489f-804f-b949ba068d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a01afc8-c8fd-4f4d-98b9-cdae731c42f0",
   "metadata": {},
   "source": [
    "### Let us analyse the association of diffferent categorical variables with the target variable Approved_Flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef15c3dc-3e00-4b1d-800b-a251ddd88b8f",
   "metadata": {},
   "source": [
    "Since we are comparing categorical VS categorical variable, we will use Chi2 - test of Independence.\n",
    "\n",
    "HYPOTHESIS:\n",
    "\n",
    "H0 : There is no significant association between the two categorical variables.\n",
    "\n",
    "H1 : There is a significant association between the two categorical variables.\n",
    "\n",
    "TEST CRITERIA:\n",
    "\n",
    "If p-value < 0.05 (alpha = 5% assumed) --> Reject null hypothesis otherwise fail to reject null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a8338c-c33e-4577-8492-761b6a857559",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']:\n",
    "    chi2,p_val, dof,exp=chi2_contingency(pd.crosstab(df[i], df['Approved_Flag']))\n",
    "    print(i,\"--->\",p_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbcaa1a-4ee4-4f63-967e-d6fc92274cae",
   "metadata": {},
   "source": [
    "### Since p-value for all the categorical variables < 0.05 , we will reject the null hypothesis. We will keep all the variables in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37afe224-8845-4a81-b711-3fb92972b336",
   "metadata": {},
   "source": [
    "### Lets test for multicollinearity in the dataset, applying sequential VIF for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efea3f1-6f4f-4dfc-b4d7-ff16451d85d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = []\n",
    "for i in df.columns:\n",
    "    if df[i].dtype != 'object' and i not in ['PROSPECTID']:\n",
    "        numeric_columns.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb84fd2-de99-412b-8572-046ca79f91d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_data = df[numeric_columns]\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5019502f-e99f-4384-9a31-c520b7c7244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VIF sequentially check\n",
    "\n",
    "# vif_data = df[numeric_columns]\n",
    "# total_columns = vif_data.shape[1]\n",
    "# columns_to_be_kept = []\n",
    "# column_index = 0\n",
    "\n",
    "\n",
    "\n",
    "# for i in range (0,total_columns):\n",
    "#     vif_value = variance_inflation_factor(vif_data, column_index)\n",
    "#     print (column_index,'---',vif_value)\n",
    "    \n",
    "    \n",
    "#     if vif_value <= 10:\n",
    "#         columns_to_be_kept.append( numeric_columns[i] )\n",
    "#         column_index = column_index+1\n",
    "    \n",
    "#     else:\n",
    "#         vif_data = vif_data.drop([ numeric_columns[i] ] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd3ec8-381e-4975-9925-72bbbe234c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate VIF for each feature\n",
    "def calculate_vif(X):\n",
    "    X = add_constant(X)\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"Feature\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif.drop(index=0)  # Drop the constant (intercept)\n",
    "\n",
    "# Function to drop all columns with VIF greater than the threshold in one pass\n",
    "def drop_high_vif_columns_once(X, threshold=8.0):\n",
    "    vif = calculate_vif(X)\n",
    "    # Find all features with VIF greater than the threshold\n",
    "    high_vif_features = vif[vif[\"VIF\"] > threshold][\"Feature\"].tolist()\n",
    "    \n",
    "    if high_vif_features:\n",
    "        print(f\"Dropping features with VIF > {threshold}: {high_vif_features}\")\n",
    "        X = X.drop(columns=high_vif_features)\n",
    "    \n",
    "    return X, vif[vif[\"Feature\"].isin(X.columns)]  # Return reduced X and updated VIF\n",
    "\n",
    "# Drop columns with VIF greater than 10\n",
    "X_reduced, final_vif = drop_high_vif_columns_once(vif_data, threshold=6.0)\n",
    "\n",
    "print(\"\\nFinal VIF values:\")\n",
    "final_vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb9c1f-0fd3-41bf-af57-304709609566",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_be_kept = final_vif['Feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2821a6ce-57cb-4738-a64e-92d79e2fa7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d6bd6b-a6e3-40c0-a02e-392df2c512e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF sequentially check\n",
    "\n",
    "#vif_data = df[numeric_columns]\n",
    "# total_columns = vif_data.shape[1]\n",
    "# columns_to_be_kept = []\n",
    "# column_index = 0\n",
    "\n",
    "\n",
    "\n",
    "# for i in range (0,total_columns):\n",
    "#     vif_value = variance_inflation_factor(vif_data, column_index)\n",
    "#     print (column_index,'---',vif_value)\n",
    "    \n",
    "    \n",
    "#     if vif_value <= 6:\n",
    "#         columns_to_be_kept.append( numeric_columns[i] )\n",
    "#         column_index = column_index+1\n",
    "    \n",
    "#     else:\n",
    "#         vif_data = vif_data.drop([ numeric_columns[i] ] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b2da38-352c-41a2-b0f4-cd8092216bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca82d04-9103-4d23-8a1f-0323ab0c33f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Anova for columns_to_be_kept \n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "columns_to_be_kept_numerical = []\n",
    "\n",
    "for i in columns_to_be_kept:\n",
    "    a = list(df[i])  \n",
    "    b = list(df['Approved_Flag'])  \n",
    "    \n",
    "    group_P1 = [value for value, group in zip(a, b) if group == 'P1']\n",
    "    group_P2 = [value for value, group in zip(a, b) if group == 'P2']\n",
    "    group_P3 = [value for value, group in zip(a, b) if group == 'P3']\n",
    "    group_P4 = [value for value, group in zip(a, b) if group == 'P4']\n",
    "\n",
    "\n",
    "    f_statistic, p_value = f_oneway(group_P1, group_P2, group_P3, group_P4)\n",
    "\n",
    "    if p_value <= 0.05:\n",
    "        columns_to_be_kept_numerical.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daa9e3a-b253-41b3-b207-a5a782c71471",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(columns_to_be_kept_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3184d8-853b-45e5-8f1d-b560d64cf4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing all the final features\n",
    "features = columns_to_be_kept_numerical + ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']\n",
    "df = df[features + ['Approved_Flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebc00a9-989c-441d-8a01-76cf81554016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a863a75-0071-4209-a28a-53f7d20f4998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding for the categorical features\n",
    "['MARITALSTATUS', 'EDUCATION', 'GENDER' , 'last_prod_enq2' ,'first_prod_enq2']\n",
    "\n",
    "\n",
    "\n",
    "df['MARITALSTATUS'].unique()    \n",
    "df['EDUCATION'].unique()\n",
    "df['GENDER'].unique()\n",
    "df['last_prod_enq2'].unique()\n",
    "df['first_prod_enq2'].unique()\n",
    "\n",
    "\n",
    "\n",
    "# Ordinal feature -- EDUCATION\n",
    "# SSC            : 1\n",
    "# 12TH           : 2\n",
    "# GRADUATE       : 3\n",
    "# UNDER GRADUATE : 3\n",
    "# POST-GRADUATE  : 4\n",
    "# OTHERS         : 1\n",
    "# PROFESSIONAL   : 3\n",
    "\n",
    "\n",
    "# Others has to be verified by the business end user \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.loc[df['EDUCATION'] == 'SSC',['EDUCATION']]              = 1\n",
    "df.loc[df['EDUCATION'] == '12TH',['EDUCATION']]             = 2\n",
    "df.loc[df['EDUCATION'] == 'GRADUATE',['EDUCATION']]         = 3\n",
    "df.loc[df['EDUCATION'] == 'UNDER GRADUATE',['EDUCATION']]   = 3\n",
    "df.loc[df['EDUCATION'] == 'POST-GRADUATE',['EDUCATION']]    = 4\n",
    "df.loc[df['EDUCATION'] == 'OTHERS',['EDUCATION']]           = 1\n",
    "df.loc[df['EDUCATION'] == 'PROFESSIONAL',['EDUCATION']]     = 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['EDUCATION'].value_counts()\n",
    "df['EDUCATION'] = df['EDUCATION'].astype(int)\n",
    "df.info()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4a2a33-b95e-429b-b00a-98b36f9968e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['MARITALSTATUS','GENDER', 'last_prod_enq2' ,'first_prod_enq2'])\n",
    "\n",
    "\n",
    "\n",
    "df_encoded.info()\n",
    "k = df_encoded.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc300a6-ad62-4afc-b0bd-10bbd71e41af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840f79d6-72df-4be9-998b-7428e644930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logestic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y = df_encoded['Approved_Flag']\n",
    "x = df_encoded.drop( ['Approved_Flag'], axis = 1)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "log_reg = LogisticRegression(solver='newton-cg')\n",
    "log_reg.fit(x_train, y_train)\n",
    "y_pred = log_reg.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print ()\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e9ae67-3bcd-42f5-abc4-7c9ff59334ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92a42e9-d05e-4dbd-8412-d3bc9f026864",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Machine Learing model fitting\n",
    "# Data processing\n",
    "\n",
    "# 1. Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators = 200, random_state=42)\n",
    "rf_classifier.fit(x_train, y_train)\n",
    "y_pred = rf_classifier.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print ()\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f903a19-a03b-4acf-8760-28bacd7adc37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e910ca15-c7af-4ef1-a2f7-2d0825be6136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Sample DataFrame\n",
    "# df = pd.DataFrame({\n",
    "#     'col_1': [value1, value2, ...],\n",
    "#     'col_2': [value1, value2, ...],\n",
    "#     'col_3': [value1, value2, ...],\n",
    "#     'col_4': [value1, value2, ...],\n",
    "#     'Approved_Flag': ['P1', 'P2', 'P3', 'P4', ...]\n",
    "# })\n",
    "\n",
    "parallel_plot_df = df[['GL_Flag','GENDER','recent_level_of_deliq','Credit_Score','Approved_Flag']]\n",
    "parallel_plot_df['Approved_Flag'] = parallel_plot_df['Approved_Flag'].astype('category').cat.codes + 1\n",
    "\n",
    "# Create the parallel coordinates plot\n",
    "fig = px.parallel_coordinates(\n",
    "    parallel_plot_df,\n",
    "    dimensions=['Credit_Score','GENDER','recent_level_of_deliq','GL_Flag'],\n",
    "    color='Approved_Flag',\n",
    "    color_continuous_scale=px.colors.sequential.Viridis,\n",
    "    #labels={'col_1': 'Feature 1', 'col_2': 'Feature 2', 'col_3': 'Feature 3', 'col_4': 'Feature 4'}\n",
    ")\n",
    "\n",
    "# Update layout for better readability\n",
    "fig.update_layout(\n",
    "    title='Parallel Coordinates Plot',\n",
    "    coloraxis_colorbar=dict(title='Approved_Flag')\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b748f9c7-e686-4491-9f92-a60dcbe8a08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d95411-dad1-45e5-ab0b-da5bdf8aa3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. xgboost\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax',  num_class=4)\n",
    "\n",
    "\n",
    "\n",
    "y = df_encoded['Approved_Flag']\n",
    "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
    "\n",
    "#Bureau 1         165\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xgb_classifier.fit(x_train, y_train)\n",
    "y_pred = xgb_classifier.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print ()\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0a929d-8c05-4693-94ad-e414aeb63f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning in xgboost\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the XGBClassifier with the initial set of hyperparameters\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=4)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "accuracy = best_model.score(x_test, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Best Hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}\n",
    "\n",
    "\n",
    "# Based on risk appetite of the bank, you will suggest P1,P2,P3,P4 to the business end user\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae4e485-aa9e-47ca-bb5c-de4b38fc3300",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ee0957-6524-4f02-a0b2-16911b06f39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44923dc-fde7-42bd-9621-08e4f1074d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_be_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050bebf4-f07a-4ccb-91aa-dd2ddfb7d38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=r2[columns_to_be_removed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf030780-c99d-4197-9161-8ae96e73443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in test.columns:\n",
    "    print(i,'-->',test[i].value_counts().get(-99999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad933a1-4afd-412c-9211-a41d395cd883",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af0e828-50db-499b-bcb5-49b8f28f18f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kan import *\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# create a KAN: 2D inputs, 1D output, and 5 hidden neurons. cubic spline (k=3), 5 grid intervals (grid=5).\n",
    "model_kan = KAN(width=[42,5,1], grid= 3, k=3 , seed=42, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f57f4c7-07a7-4263-bbe8-ec9458756d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81404281-ae31-4f87-a952-a5d723ff85af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c97306-b302-4e93-b10d-052a77b6827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x['Approved_Flag'] = y.map({'P1':1 , 'P2':2, 'P3':3 , 'P4':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae86325-8208-4d84-bc0b-98455b064454",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e8436-53de-4c3e-a4d3-68f49fcb8bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_P1 = x[y == 'P1']\n",
    "x_P2 = x[y == 'P2']\n",
    "x_P3 = x[y == 'P3']\n",
    "x_P4 = x[y == 'P4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87774cf7-a194-48fa-b63f-d8bd76b6ef63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_downsampled = x_P1.sample(200 , random_state= 42)\n",
    "x2_downsampled = x_P2.sample(200 , random_state= 42)\n",
    "x3_downsampled = x_P3.sample(200 , random_state= 42)\n",
    "x4_downsampled = x_P4.sample(200 , random_state= 42)\n",
    "\n",
    "X_downsampled = pd.concat([x1_downsampled,x2_downsampled,x3_downsampled,x4_downsampled])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18454323-2069-4144-9284-90f708fa6fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_downsampled = X_downsampled.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa6f6cd-ca1a-415d-9e79-d7fb00fe4ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d3907-e079-4c83-bc7e-b7b4f939fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_downsampled.drop(['Approved_Flag'] , axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9147b93-3aa0-4f49-9dec-748e1f0aae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7226b95-1ed0-4ba9-bd9f-e81c6195c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X_downsampled['Approved_Flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405497a9-c6a8-4e77-a875-a7db45e8931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6593e4-2d4a-4cea-8d59-ebf88d2e8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X and y are already loaded as DataFrames/Series\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Store the splits in a dictionary\n",
    "X_t = X_train.values\n",
    "X_t_64 = X_t.astype(np.float64)\n",
    "X_te = X_test.values\n",
    "X_te_64 = X_te.astype(np.float64)\n",
    "dataset = {\n",
    "    'train_input': torch.tensor(X_t_64, dtype=torch.float64),\n",
    "    'train_label': torch.tensor(y_train.values, dtype=torch.float64),\n",
    "    'test_input': torch.tensor(X_te_64, dtype=torch.float64),\n",
    "    'test_label': torch.tensor(y_test.values, dtype=torch.float64)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a9fb77-3a68-4c1b-b223-55ca8cc7eab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train_input'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8549990b-70a8-4dc4-9715-4b613468ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['test_label'].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a723f77-e678-44a6-bb5d-78088314426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kan(dataset['train_input'])\n",
    "model_kan.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3dcaa0-ac80-4376-922a-309e1e25f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kan.train()\n",
    "model_kan.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bd8a88-8dea-4326-9ed9-155d4cd5d65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kan.prune()\n",
    "model_kan.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30540ef-f990-470e-8e0f-47d932e3c44c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d7f895-d641-43c7-b50e-00215fb63116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cd4f1e-17f4-44e8-aa04-db58f833ca61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
